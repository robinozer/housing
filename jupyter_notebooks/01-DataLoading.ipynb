{
  "cells": [
    {
      "source": [
        "# **Notebook 1: Load data and data cleaning**"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch data from Kaggle and save as raw data \n",
        "* Inspect data\n",
        "* Save raw datasets\n",
        "* Save cleaned data under outputs/datasets/cleaned\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle dataset downloaded from https://www.kaggle.com/datasets/codeinstitute/housing-prices-data\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Raw datasets are found in folder inputs/dataset/raw/house_prices\n",
        "* Generate Dataset: outputs/datasets/collection/house_prices_records.csv\n",
        "* Generate cleaned datasets: outputs/datasets/cleaned/house_prices_records_cleaned.csv and outputs/datasets/cleaned/inherited_houses_cleaned.csv\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* Data cleaning pipeline\n",
        "* Drop variables: `['EnclosedPorch', 'WoodDeckSF' ]`\n",
        "* Use median and mode imputation to replace missing values in numerical and categorical variables respectively.\n",
        "* Handle mismatching data types by converting floats into integers\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/workspaces/housing/jupyter_notebooks'"
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You set a new current directory\n"
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/workspaces/housing'"
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1: Load and inspect the data"
      ]
    },
    {
      "source": [
        "The data has been downloaded from: https://www.kaggle.com/datasets/codeinstitute/housing-prices-data\n",
        "\n",
        "First we create the folders in the file path"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[Errno 17] File exists: 'inputs/datasets/raw/house_prices'\n"
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='inputs/datasets/raw/house_prices')\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "source": [
        "Then drag and drop both csv files to the folder. \n",
        "- house-metadata.txt can be dragged and dropped to inputs/datasets/raw for reference."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading the data and showing first rows to get an idea of the data I'm working with."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n0       856     854.0           3.0           No         706          GLQ   \n1      1262       0.0           3.0           Gd         978          ALQ   \n2       920     866.0           3.0           Mn         486          GLQ   \n3       961       NaN           NaN           No         216          ALQ   \n4      1145       NaN           4.0           Av         655          GLQ   \n\n   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotFrontage  \\\n0        150            0.0         548          RFn  ...         65.0   \n1        284            NaN         460          RFn  ...         80.0   \n2        434            0.0         608          RFn  ...         68.0   \n3        540            NaN         642          Unf  ...         60.0   \n4        490            0.0         836          RFn  ...         84.0   \n\n   MasVnrArea OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  WoodDeckSF  \\\n0       196.0          61            5            7          856         0.0   \n1         0.0           0            8            6         1262         NaN   \n2       162.0          42            5            7          920         NaN   \n3         0.0          35            5            7          756         NaN   \n4       350.0          84            5            8         1145         NaN   \n\n   YearBuilt  YearRemodAdd  SalePrice  \n0       2003          2003     208500  \n1       1976          1976     181500  \n2       2001          2002     223500  \n3       1915          1970     140000  \n4       2000          2000     250000  \n\n[5 rows x 24 columns]\n"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the historical house prices records data\n",
        "records_df = pd.read_csv('inputs/datasets/raw/house_prices/house_prices_records.csv')\n",
        "\n",
        "# Load the inherited houses data\n",
        "inherited_df = pd.read_csv('inputs/datasets/raw/house_prices/inherited_houses.csv')\n",
        "\n",
        "# Check the first few rows of each DataFrame\n",
        "print(records_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n0       896         0             2           No       468.0          Rec   \n1      1329         0             3           No       923.0          ALQ   \n2       928       701             3           No       791.0          GLQ   \n3       926       678             3           No       602.0          GLQ   \n\n   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotArea  \\\n0      270.0              0       730.0          Unf  ...    11622   \n1      406.0              0       312.0          Unf  ...    14267   \n2      137.0              0       482.0          Fin  ...    13830   \n3      324.0              0       470.0          Fin  ...     9978   \n\n   LotFrontage MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  \\\n0         80.0        0.0            0            6            5        882.0   \n1         81.0      108.0           36            6            6       1329.0   \n2         74.0        0.0           34            5            5        928.0   \n3         78.0       20.0           36            6            6        926.0   \n\n   WoodDeckSF  YearBuilt  YearRemodAdd  \n0         140       1961          1961  \n1         393       1958          1958  \n2         212       1997          1998  \n3         360       1998          1998  \n\n[4 rows x 23 columns]\n"
        }
      ],
      "source": [
        "print(inherited_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2: Data overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Explore the data to spot any anomalies. First let's take a look at records_df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 24 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   1stFlrSF       1460 non-null   int64  \n 1   2ndFlrSF       1374 non-null   float64\n 2   BedroomAbvGr   1361 non-null   float64\n 3   BsmtExposure   1460 non-null   object \n 4   BsmtFinSF1     1460 non-null   int64  \n 5   BsmtFinType1   1346 non-null   object \n 6   BsmtUnfSF      1460 non-null   int64  \n 7   EnclosedPorch  136 non-null    float64\n 8   GarageArea     1460 non-null   int64  \n 9   GarageFinish   1298 non-null   object \n 10  GarageYrBlt    1379 non-null   float64\n 11  GrLivArea      1460 non-null   int64  \n 12  KitchenQual    1460 non-null   object \n 13  LotArea        1460 non-null   int64  \n 14  LotFrontage    1201 non-null   float64\n 15  MasVnrArea     1452 non-null   float64\n 16  OpenPorchSF    1460 non-null   int64  \n 17  OverallCond    1460 non-null   int64  \n 18  OverallQual    1460 non-null   int64  \n 19  TotalBsmtSF    1460 non-null   int64  \n 20  WoodDeckSF     155 non-null    float64\n 21  YearBuilt      1460 non-null   int64  \n 22  YearRemodAdd   1460 non-null   int64  \n 23  SalePrice      1460 non-null   int64  \ndtypes: float64(7), int64(13), object(4)\nmemory usage: 273.9+ KB\nNone\n"
        }
      ],
      "source": [
        "print(records_df.info())\n"
      ]
    },
    {
      "source": [
        "And show missing values:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(records_df.isnull().sum())"
      ]
    },
    {
      "source": [
        "Then we do the same for inherited_df:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(inherited_df.info())"
      ]
    },
    {
      "source": [
        "And explore missing values for inherited houses. There are none here!"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(inherited_df.isnull().sum())"
      ]
    },
    {
      "source": [
        "Great, now we have taken a first look at the date and can start doing some initial cleaning."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Section 3: Cleaning - Data types mismatch"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "At this point, we spot that the data types vary between the records_df dataset and inherited_df dataset on numerous variables. Is this a problem?"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Well, discrepancies between the data types in records_df and inherited_df for the same variables can cause issues down the line, especially when building and using predictive models.\n",
        "\n",
        "Most machine learning algorithms require the input data to be in a consistent format. If a variable is represented as an integer in one dataset and as a float in another, the algorithm may get confused and produce unreliable results.\n",
        "\n",
        "To address this, we should make sure that the same variables have the same data types in both datasets. Given that these variables represent counts (i.e., the number of square feet, the number of bedrooms), it would make more sense for them to be integers."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "First we take a look at a sample of the data (top 20 rows), and see that the floats seem to be whole numbers. \n",
        "\n",
        "Therefore, in the cases where a variable is a float in one dataset and an integer in the other, it will be converted into an integer in both."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(records_df.head(20))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(inherited_df.head())"
      ]
    },
    {
      "source": [
        "So we convert the variables listed below from the records_df dataframe to integers. Please note that the variable \"GarageYrBlt\" was also converted from a float to an integer in both datasets. This was not because of a data type mismatch, but because it made more sense to have the variable as an integer, as year values typically represent whole numbers and don't usually involve decimal points.\n",
        "\n",
        "Given that there are missing values in some of the columns that we want to convert, we'll use the nullable integer type \"Int64\". Note that this type is case sensitive."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "float_cols_records = ['2ndFlrSF', 'BedroomAbvGr', 'EnclosedPorch', 'LotFrontage', 'MasVnrArea', 'WoodDeckSF', 'GarageYrBlt']\n",
        "\n",
        "for col in float_cols_records:\n",
        "    records_df[col] = records_df[col].astype('Int64')\n"
      ]
    },
    {
      "source": [
        "Now let's do the same for the inherited_df dataframe. In this case there are no missing values, so we can use the \"int64\" type."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "float_cols_inherited = ['BsmtFinSF1', 'BsmtUnfSF', 'GarageArea', 'TotalBsmtSF', 'LotFrontage', 'MasVnrArea', 'GarageYrBlt']\n",
        "\n",
        "for col in float_cols_inherited:\n",
        "    inherited_df[col] = inherited_df[col].astype('int64')\n"
      ]
    },
    {
      "source": [
        "Now we check the data types again to ensure the conversion was successful. First for the records_df:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(records_df.info())\n"
      ]
    },
    {
      "source": [
        "And here for inherited_df. Comparing them, we see that the data types for all variables match between the datasets, which will make analyses more reliable."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(inherited_df.info())"
      ]
    },
    {
      "source": [
        "# Section 4: Cleaning - Handle missing data values"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Moving on, we proceed with handling missing data values. To refresh, here are the numbers of missing data in records_df. There were no missing data values in the inherited_df."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(records_df.isnull().sum())"
      ]
    },
    {
      "source": [
        "Looking at the missing values in records_df, columns 'EnclosedPorch' and 'WoodDeckSF' have a lot of missing values (over 80% of the data). Filling these missing values may not give us reliable data, so we choose the approach of dropping these columns. \n",
        "\n",
        "For other columns, we fill missing values with a reasonable strategy - using the median value for numerical columns and the most frequent value for categorical columns."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop columns with too many missing values\n",
        "records_df = records_df.drop(['EnclosedPorch', 'WoodDeckSF'], axis=1)\n",
        "inherited_df = inherited_df.drop(['EnclosedPorch', 'WoodDeckSF'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values in numerical columns with the median\n",
        "for col in ['2ndFlrSF', 'BedroomAbvGr', 'GarageYrBlt', 'LotFrontage', 'MasVnrArea']:\n",
        "    records_df[col] = records_df[col].fillna(records_df[col].median())\n",
        "    inherited_df[col] = inherited_df[col].fillna(inherited_df[col].median())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fill missing values in categorical columns with the most frequent value\n",
        "for col in ['BsmtFinType1', 'GarageFinish']:\n",
        "    records_df[col] = records_df[col].fillna(records_df[col].mode()[0])\n",
        "    inherited_df[col] = inherited_df[col].fillna(inherited_df[col].mode()[0])"
      ]
    },
    {
      "source": [
        "Then we print out the count of missing values in each column to confirm that there are no missing values left"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(records_df.isnull().sum())"
      ]
    },
    {
      "source": [
        "And for inherited_df also here below, just for consistency. We can see here that the dropped variables are no longer visible."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(inherited_df.isnull().sum())"
      ]
    },
    {
      "source": [
        "Great! Now the dataset has no missing values and the data types are the same in both datasets."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "source": [
        "## Save data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        " Create a collection folder for records_df and manually drag and drop a copy of the raw dataset there for future use."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[Errno 17] File exists: 'outputs/datasets/collection'\n"
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  os.makedirs(name='outputs/datasets/collection') # create outputs/datasets/collection folder\n",
        "except Exception as e:\n",
        "  print(e)"
      ]
    },
    {
      "source": [
        "Now we create folders for the cleaned data and save it to new CSV files."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Define file paths\n",
        "records_file_path = 'outputs/datasets/cleaned/house_prices_records_cleaned.csv'\n",
        "inherited_file_path = 'outputs/datasets/cleaned/inherited_houses_cleaned.csv'\n",
        "\n",
        "# Create the directories in the file path\n",
        "os.makedirs(os.path.dirname(records_file_path), exist_ok=True)\n",
        "os.makedirs(os.path.dirname(inherited_file_path), exist_ok=True)\n",
        "\n",
        "# Save the CSV files\n",
        "records_df.to_csv(records_file_path, index=False)\n",
        "inherited_df.to_csv(inherited_file_path, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "source": [
        "Great! Now you can  push the changes to your GitHub Repo, using the Git commands (git add, git commit, git push)"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python381264bit3812pyenvc44d0ba3d4d74926a1a78ae71e39f6ac"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12-final"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}