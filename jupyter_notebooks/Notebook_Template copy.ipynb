{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Notebook 3: Feature Engineering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Generate train and test sets for feature engineering.\n",
        "* Engineer features for Classification, Regression and Cluster models\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/house_prices_records_cleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Train and Test sets from cleaned data, saved under outputs/datasets/cleaned/train and outputs/datasets/cleaned/test\n",
        "\n",
        "## Comment\n",
        "\n",
        "* For readers of this notebook, previously the name of the main dataframe used in this project has been called 'records_df'. From this notebook on, the main dataframe will simply be 'df'. In this notebook, we split df into train and test sets, and their respective names will reflect this also.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_raw_path = \"outputs/datasets/cleaned/house_prices_records_cleaned.csv\"\n",
        "df = pd.read_csv(df_raw_path)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Split train and test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "In the cell below, the target variable 'SalePrice' is separated out from the rest of the data, and the split produces both a train and test set for the features (TrainSet and TestSet) and the target (train_target and test_target).\n",
        "\n",
        "The reason for changing the code from the walkthrough is that in the train_test_split() function, I was passing df('SalePrice') as the target variable, but also including it in my df, which means my target variable 'SalePrice' would be present in both my features and targets, which is not what I would typically want."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features = df.drop('SalePrice', axis=1)  # drop the target variable from the feature set\n",
        "target = df['SalePrice']\n",
        "\n",
        "TrainSet, TestSet, train_target, test_target = train_test_split(\n",
        "    features,\n",
        "    target,\n",
        "    test_size=0.2,\n",
        "    random_state=0\n",
        ")\n",
        "\n",
        "print(f\"TrainSet shape: {TrainSet.shape} \\nTestSet shape: {TestSet.shape}\")\n"
      ]
    },
    {
      "source": [
        "As we see in the output, the train set has 1168 rows which is 80% of the data, and the test set accounts for the remaining 20%."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "We then save the train and test set respectively in their folders."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TrainSet.to_csv(\"outputs/datasets/cleaned/train/TrainSetCleaned.csv\", index=False)\n",
        "TestSet.to_csv(\"outputs/datasets/cleaned/test/TestSetCleaned.csv\", index=False)"
      ]
    },
    {
      "source": [
        "And we also save the datasets where we put the target variable."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_target.to_csv(\"outputs/datasets/cleaned/train/TrainSetTarget.csv\", index=False)\n",
        "test_target.to_csv(\"outputs/datasets/cleaned/test/TestSetTarget.csv\", index=False)"
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note: Since the first notebooks in this project are not identical to those of the walkthrough project Churnometer, namely we did data cleaning before the EDA and analyses (which is a valid approach), we will therefore assess correlation levels and PPS here before starting the feature engineering process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "Display at heatmaps:"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# FEATURE ENGINEERING"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "Now we move on to Feature Engineering.\n",
        "\n",
        "In this section we will handle outliers, encode categorical variables, transform features and create new features. "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Load cleaned training and test sets"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "TrainSet_df = pd.read_csv(\"outputs/datasets/cleaned/train/TrainSetCleaned.csv\")\n",
        "TestSet_df = pd.read_csv(\"outputs/datasets/cleaned/test/TestSetCleaned.csv\")\n",
        "\n",
        "# Check the first few rows of the DataFrame to confirm that it loaded correctly\n",
        "TrainSet_df.head()\n",
        "TestSet_df.head()"
      ]
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Feature Engineering Analysis"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from feature_engine import transformation as vt\n",
        "from feature_engine.outliers import Winsorizer\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "sns.set(style=\"whitegrid\")\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "def FeatureEngineeringAnalysis(df, analysis_type='numerical'):\n",
        "    \"\"\"\n",
        "    - used for quick feature engineering on numerical and categorical variables\n",
        "    to decide which transformation can better transform the distribution shape\n",
        "    - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
        "    \"\"\"\n",
        "    check_missing_values(df)\n",
        "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
        "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
        "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
        "\n",
        "    # Loop in each variable and engineer the data according to the analysis type\n",
        "    df_feat_eng = pd.DataFrame([])\n",
        "    for column in df.columns:\n",
        "        # create additional columns (column_method) to apply the methods\n",
        "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
        "        for method in list_column_transformers:\n",
        "            df_feat_eng[f\"{column}_{method}\"] = df[column]\n",
        "\n",
        "        # Apply transformers in respective column_transformers\n",
        "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
        "            analysis_type, df_feat_eng, column)\n",
        "\n",
        "        # For each variable, assess how the transformations perform\n",
        "        transformer_evaluation(\n",
        "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
        "\n",
        "    return df_feat_eng\n",
        "\n",
        "\n",
        "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
        "    \"\"\" Check analysis type \"\"\"\n",
        "    if analysis_type is None:\n",
        "        raise SystemExit(\n",
        "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
        "    if analysis_type not in allowed_types:\n",
        "        raise SystemExit(\n",
        "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
        "\n",
        "\n",
        "def check_missing_values(df):\n",
        "    if df.isna().sum().sum() != 0:\n",
        "        raise SystemExit(\n",
        "            f\"There is a missing value in your dataset. Please handle that before getting into feature engineering.\")\n",
        "\n",
        "\n",
        "def define_list_column_transformers(analysis_type):\n",
        "    \"\"\" Set suffix columns according to analysis_type\"\"\"\n",
        "    if analysis_type == 'numerical':\n",
        "        list_column_transformers = [\n",
        "            \"log_e\", \"log_10\", \"reciprocal\", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        list_column_transformers = [\"ordinal_encoder\"]\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        list_column_transformers = ['iqr']\n",
        "\n",
        "    return list_column_transformers\n",
        "\n",
        "\n",
        "def apply_transformers(analysis_type, df_feat_eng, column):\n",
        "    for col in df_feat_eng.select_dtypes(include='category').columns:\n",
        "        df_feat_eng[col] = df_feat_eng[col].astype('object')\n",
        "\n",
        "    if analysis_type == 'numerical':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_Numerical(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'outlier_winsorizer':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_OutlierWinsorizer(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    elif analysis_type == 'ordinal_encoder':\n",
        "        df_feat_eng, list_applied_transformers = FeatEngineering_CategoricalEncoder(\n",
        "            df_feat_eng, column)\n",
        "\n",
        "    return df_feat_eng, list_applied_transformers\n",
        "\n",
        "\n",
        "def transformer_evaluation(column, list_applied_transformers, analysis_type, df_feat_eng):\n",
        "    # For each variable, assess how the transformations perform\n",
        "    print(f\"* Variable Analyzed: {column}\")\n",
        "    print(f\"* Applied transformation: {list_applied_transformers} \\n\")\n",
        "    for col in [column] + list_applied_transformers:\n",
        "\n",
        "        if analysis_type != 'ordinal_encoder':\n",
        "            DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        else:\n",
        "            if col == column:\n",
        "                DiagnosticPlots_Categories(df_feat_eng, col)\n",
        "            else:\n",
        "                DiagnosticPlots_Numerical(df_feat_eng, col)\n",
        "\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    sns.countplot(data=df_feat_eng, x=col, palette=[\n",
        "                  '#432371'], order=df_feat_eng[col].value_counts().index)\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.suptitle(f\"{col}\", fontsize=30, y=1.05)\n",
        "    plt.show()\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n",
        "def DiagnosticPlots_Numerical(df, variable):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n",
        "    sns.histplot(data=df, x=variable, kde=True, element=\"step\", ax=axes[0])\n",
        "    stats.probplot(df[variable], dist=\"norm\", plot=axes[1])\n",
        "    sns.boxplot(x=df[variable], ax=axes[2])\n",
        "\n",
        "    axes[0].set_title('Histogram')\n",
        "    axes[1].set_title('QQ Plot')\n",
        "    axes[2].set_title('Boxplot')\n",
        "    fig.suptitle(f\"{variable}\", fontsize=30, y=1.05)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def FeatEngineering_CategoricalEncoder(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "    try:\n",
        "        encoder = OrdinalEncoder(encoding_method='arbitrary', variables=[\n",
        "                                 f\"{column}_ordinal_encoder\"])\n",
        "        df_feat_eng = encoder.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_ordinal_encoder\")\n",
        "\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_ordinal_encoder\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_OutlierWinsorizer(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # Winsorizer iqr\n",
        "    try:\n",
        "        disc = Winsorizer(\n",
        "            capping_method='iqr', tail='both', fold=1.5, variables=[f\"{column}_iqr\"])\n",
        "        df_feat_eng = disc.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_iqr\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked\n",
        "\n",
        "\n",
        "def FeatEngineering_Numerical(df_feat_eng, column):\n",
        "    list_methods_worked = []\n",
        "\n",
        "    # LogTransformer base e\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_e\"])\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_e\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_e\"], axis=1, inplace=True)\n",
        "\n",
        "    # LogTransformer base 10\n",
        "    try:\n",
        "        lt = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
        "        df_feat_eng = lt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_log_10\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inplace=True)\n",
        "\n",
        "    # ReciprocalTransformer\n",
        "    try:\n",
        "        rt = vt.ReciprocalTransformer(variables=[f\"{column}_reciprocal\"])\n",
        "        df_feat_eng = rt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_reciprocal\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=True)\n",
        "\n",
        "    # PowerTransformer\n",
        "    try:\n",
        "        pt = vt.PowerTransformer(variables=[f\"{column}_power\"])\n",
        "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_power\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_power\"], axis=1, inplace=True)\n",
        "\n",
        "    # BoxCoxTransformer\n",
        "    try:\n",
        "        bct = vt.BoxCoxTransformer(variables=[f\"{column}_box_cox\"])\n",
        "        df_feat_eng = bct.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_box_cox\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
        "\n",
        "    # YeoJohnsonTransformer\n",
        "    try:\n",
        "        yjt = vt.YeoJohnsonTransformer(variables=[f\"{column}_yeo_johnson\"])\n",
        "        df_feat_eng = yjt.fit_transform(df_feat_eng)\n",
        "        list_methods_worked.append(f\"{column}_yeo_johnson\")\n",
        "    except Exception:\n",
        "        df_feat_eng.drop([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
        "\n",
        "    return df_feat_eng, list_methods_worked"
      ],
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* If you do not need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}