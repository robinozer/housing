{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "0aStgWSO0E0E"
            },
            "source": [
                "# **Notebook 3: Feature Engineering**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "1eLEkw5O0ECa"
            },
            "source": [
                "## Objectives\n",
                "\n",
                "* Generate train and test sets for feature engineering.\n",
                "* Engineer features for Classification, Regression and Cluster models\n",
                "\n",
                "## Inputs\n",
                "\n",
                "* outputs/datasets/cleaned/house_prices_records_cleaned.csv\n",
                "\n",
                "## Outputs\n",
                "\n",
                "* Generate Train and Test sets from cleaned data, saved under outputs/datasets/cleaned/train and outputs/datasets/cleaned/test\n",
                "\n",
                "## Conclusions\n",
                "\n",
                "* In case you have any additional comments that don't fit in the previous bullets, please state them here. \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "9uWZXH9LwoQg"
            },
            "source": [
                "---"
            ]
        },
        {
            "cell_type": "markdo      wn",
            "m    etadata": {
                "id": "cqP-UeN-z3i2      "
            },
            "sour        ce": [
                "# Change wo      rking dir      ectory"
            ]
        },
        {
            "ce    ll_type    ": "mark      down",
            "metadata": {},
            "source": [
                "* We are assuming you wi      ll store       the notebooks in a s        ubfolder, therefore when running th      e note    book in     the edi      tor, you will need to change th      e working directory"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "aOGIGS-uz3i2"
            },
            "source": [
                "We need to change the working directory from its cur      rent f    older t    o its pa      rent folder\n",
                "* We a      ccess the current dire        ctory with os.getcwd()"
            ]
        },
        {
            "cell        _type": "code",
            "execution_count": 1,
            "metadata": {
                "id": "wZfF_j-Bz3i4",
                "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
            },
            "o    utputs": [
                {
                    "out      put_type": "execute_result",
                    "data": {
                        "text/plain": "'/wo        rkspaces/housing/jupyter_notebooks'"
                    },
                    "metad      ata": {},
                    "        execution_co          unt": 1
                }
            ],
            "source": [
                "import os\n            ",
                "current_dir = os.getcwd()\n",
                "current_dir"
            ]
        },
        {
            "cell_type": "          markdown",
            "metadata": {
                "id": "      9MWW8E7lz3i7"
            },
            "source": [
                "We want to make the parent of th        e current directory       the ne    w curre    nt direc      tory\n",
                "* os.path.dir      name() gets the parent         directory\n",
                "* o      s.chir()       defines the new curr        ent directory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "id": "TwHsQRWjz3i9",
                "        outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
                "    tags": []
            },
            "outputs": [
                {
                    "output_type      ": "stream",
                    "name": "stdout",
                    "        text": "You set a new current directory\n"
                }
            ],
            "source": [
                "os.chdir(os.path.d        irname(curre          nt_dir))\n",
                "print(\"You s          et a new current directory\"          )"
            ]
        },
        {
            "cell_type": "markdown        ",
            "metadat      a": {
                "id": "M_xPk_Ijz3i-"
            },
            "source": [
                "C        onfirm the new current directory"
            ]
        },
        {
            "ce    ll_type": "code",
            "execution_coun      t": 3,
            "metadata        ": {
                "id": "vz3S-_k      jz3jA",
                "outputId": "        00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
            },
            "o    utputs": [
                {
                    "out      put_type": "execute_result",
                    "data": {
                        "text/plain": "'/wo        rkspaces/housing'"
                    },
                    "metadata": {},
                    "execution_count": 3
                }
            ],
            "source": [
                "current          _dir = os.getcwd()\n",
                "current_dir"
            ]
        },
        {
            "cell_type": "markdown",
            "metad          ata": {
                "id": "-mavJ8        DibrcQ"
            },
            "source": [
                "# Load data"
            ]
        },
        {
            "cell_type": "code    ",
            "execu      tion_count": 4,
            "metadata      ": {},
            "outputs": [
                {
                    "ou      tput_type      ": "execute_result",
                    "data": {
                        "text/pl      ain": "   1stFlrSF  2ndFlrS      F  BedroomAbvGr BsmtExposure        BsmtFinSF1 BsmtFinTy      pe1  \\\n0       856               854                       3           No         706                    GLQ   \n1      1262                     0             3           Gd         978          ALQ   \n2       920       866             3           Mn         486          GLQ   \n\n   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n0        150         548          RFn         2003  ...     8450          65   \n1        284         460          RFn         1976  ...     9600          80   \n2        434         608          RFn         2001  ...    11250          68   \n\n   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n0         196           61            5            7          856       2003   \n1           0            0            8            6         1262       1976   \n2         162           42            5            7          920       2001   \n\n   YearRemodAdd  SalePrice  \n0          2003     208500  \n1          1976     181500  \n2          2002     223500  \n\n[3 rows x 22 columns]",
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n                }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>BedroomAbvGr</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtUnfSF</th>\n      <th>GarageArea</th>\n      <th>GarageFinish</th>\n      <th>GarageYrBlt</th>\n      <th>...</th>\n      <th>LotArea</th>\n      <th>LotFrontage</th>\n      <th>MasVnrArea</th>\n      <th>OpenPorchSF</th>\n      <th>OverallCond</th>\n      <th>OverallQual</th>\n      <th>TotalBsmtSF</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>856</td>\n      <td>854</td>\n      <td>3</td>\n      <td>No</td>\n      <td>706</td>\n      <td>GLQ</td>\n      <td>150</td>\n      <td>548</td>\n      <td>RFn</td>\n      <td>2003</td>\n      <td>...</td>\n      <td>8450</td>\n      <td>65</td>\n      <td>196</td>\n      <td>61</td>\n      <td>5</td>\n      <td>7</td>\n      <td>856</td>\n      <td>2003</td>\n      <td>2003</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1262</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Gd</td>\n      <td>978</td>\n      <td>ALQ</td>\n      <td>284</td>\n      <td>460</td>\n      <td>RFn</td>\n      <td>1976</td>\n      <td>...</td>\n      <td>9600</td>\n      <td>80</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>6</td>\n      <td>1262</td>\n      <td>1976</td>\n      <td>1976</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920</td>\n      <td>866</td>\n      <td>3</td>\n      <td>Mn</td>\n      <td>486</td>\n      <td>GLQ</td>\n      <td>434</td>\n      <td>608</td>\n      <td>RFn</td>\n      <td>2001</td>\n      <td>...</td>\n      <td>11250</td>\n      <td>68</td>\n      <td>162</td>\n      <td>42</td>\n      <td>5</td>\n      <td>7</td>\n      <td>920</td>\n      <td>2001</td>\n      <td>2002</td>\n      <td>223500</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 22 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 4
                }
            ],
            "source": [
                "import pandas as pd\n",
                "df_raw_path = \"outputs/datasets/cleaned/hou          se_prices_rec          ords_cleaned.csv\"\n",
                "df = pd.read_csv(df_raw        _path)\n      ",
                "df.head(3)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "uFQo3ycuO-v6"
            },
            "source": [
                "# Split train and test data"
            ]
        },
        {
            "c    ell_typ    e": "mar      kdown",
            "metadata": {},
            "source": [
                "In the cell below, the       target va      riable 'SalePrice' i        s separated out from the rest of the       data,     and th    e split       produces both a train and test       set for the features (      TrainSet and TestSet        ) and the target (train_target and test_target).\n",
                "\n",
                "The reason for changing the code from the walkthrough is that in the train_test_split() function, I was passing df(['SalePrice']) as the target variable, but also inclu        ding it in my         df, which means my target variable 'SalePrice' would be present in both my features and targets, which is not what I would typically want."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "na    me": "st      dout",
                    "text": "T      rainSet shape: (1168, 21) \n      TestSet shape: (292, 2        1)\n"
                }
            ],
            "source": [
                "feature          s = df.drop('SalePrice', axis=1)  #           drop the target variable fr          om the feature set\n",
                "target = df['SalePrice']\n",
                "\n",
                "TrainSe      t, TestSet, train_ta        rget, test_target = train_test_split(\n",
                "    features,\n        ",
                "            target,\n",
                "    test_size=0.2,\n",
                "    random_state=0\n",
                ")\n",
                "        \n",
                "print(f\"TrainSet shape:         {TrainSet.sha        pe} \\nTestSet shape: {TestSet.shape}\")\n"
            ]
        },
        {
            "source        ": [
                "As we see in         the output, the train set         has 1168 rows which is 80% of t        he data, and the test set accoun        ts for the re      maining 20%.    "
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "We th        en sav      e the train and te      st set respectively in their folders."
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "Train    Set.to_csv(\"outputs/datasets/c    leaned/train/TrainSetCl      eaned.c        sv\",       index=False)\n",
                "TestSet.to_csv(\"outputs/datasets/cleaned/test/TestSetCleaned.csv\",       index=F    alse)"
            ],
            "cell_typ    e": "code",
            "meta      data": {},
            "execution_cou      nt": 23,
            "outputs": []
        },
        {
            "source": [
                "And we also save the datasets       where we put the target variable."
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "exec    ution_count": 18,
            "met    adata": {},
            "out      puts": [],
            "source": [
                "train_target.to_csv(\"outputs/datasets/cleaned/train/TrainSetTarget      .csv\",     index=False)\n",
                "test    _target.to_csv(\"output      s/datas      ets/cl      eaned/test/TestSetTarget.cs      v\", index=False)"
            ]
        },
        {
            "source        ": [],
            "cell_ty        pe": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "\n"
            ],
            "cell_type": "mark    down",
            "metadata": {}
        },
        {
            "source": [
                "# Correlation and PPS Analy    sis"
            ],
            "ce      ll_type": "markdow    n",
            "metadata": {}
        },
        {
            "source": [
                "*       Since we did data       cleaning befo      re the     EDA and analyses, we donâ€™t expe    ct any changes in corre      lation         levels       and PPS compared       to the previous notebook."
            ],
            "cell_    type": "markdown",
            "metad    ata": {}
        },
        {
            "s        ource": [],
            "cell_      type": "markdown",
            "metadata": {}
        },
        {
            "source": [],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source      ": [
                "# FEATURE ENGINEERING      "
            ],
            "cell_type": "mark      down",
            "metadata": {}
        },
        {
            "source": [
                "Now we move on to Feature Engineering.      \n",
                "\n",
                "In this secti      on we will handle outliers, encode categorical variables, tra      nsform features and create new features. \n"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "sou      rce": [
                "# Load cleaned training and test sets"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "o    utput_type": "execute_result",
                    "data": {
                        "text/plain": "   1st      FlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType      1  \\\n0      2515         0             4                 No        1219          Rec       \n1       9    58       620                   3           No         403          BLQ   \n2       979       224                     3           No         185                LwQ   \n3      1156       866             4           No               392          BLQ   \n4       525         0                   3           No           0          Unf   \n\n       BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  KitchenQual LotArea  \\\n0        81    6         484          Unf         1975  ...           TA   32668   \n1        238         240                Unf         1941  ...           Fa    9490   \n2        524         352                  Unf         1950  ...           Gd    701        5   \n3        768         505                  Fin               1977        ...           TA   10005   \n4        525               264          Unf         1971  ...           TA    1680       \n\n   LotFrontage  MasVnrArea  OpenPorchSF  OverallCond  Ov    erallQual  \\\n0                 69           0            0            3                    6   \n1           79           0            0            7            6   \n2           69         161                  0                  4            5   \n3           83         299          117            5            7   \n4           2      1         381            0            5            6   \n\n   TotalBsmtSF  YearBuilt  YearRemodAdd      \n0         2035       1957          1975  \n1              806             1941          1950  \n2          709       1950          1950  \n3               1160             1977                1977  \n4          525       1971          1971  \n\n[5 rows x 21 columns]",
                        "text/html": "<div>\        n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        ve          rtical-align:           middle;\n    }\n\n    .dataframe t            body tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=            \"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1stFlrSF          </th>\n      <          th>2ndFlrSF</th>\n      <th>Bedr          oomAbvGr</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinSF1        </th>\n      <th>BsmtFinType1</th>\n      <th>BsmtUnfSF</th>\n            <th>GarageArea</th>\n      <th>GarageFinish</th>\n      <th>GarageYrBlt</th>\n      <th>...</th>\n      <th>Kitche      nQual</th>\n              <th>LotArea</th>\n      <th>Lo        tFrontage</th>\n      <th>MasVnrArea</th>\n      <th>OpenPorchSF<        /th>\n      <th>OverallCond</th>\n      <th>OverallQual</th>\n      <th>TotalBsmtSF</th>\n      <th>Ye        arBuilt</th>\n      <th>YearRemodAdd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>        2515</td>\n              <td>0</td>\n      <td>4</td>\        n      <td>No</td>\n      <td>1219</td>\n      <td>Rec</td>\n      <td>816        </td>\n      <td>484</td>\n      <td>Unf</td>\n      <td>1975</td>\n      <td>...</td>\n      <td      >TA</td>\n      <td>32668</td>\n      <td>69</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n          <td>6</td>\n      <td>2035</td>\n      <td>1957</td>\n      <td>1975</td>\n    </tr>\n    <tr>\n      <t    h>1</th>\n            <td>958</td>\n      <t      d>620</td>\n      <td>      3</td>\n      <td>No</td>\n          <td>403</td>\n          <td      >BLQ</td        >\n      <td>238</        td>\n      <td>240</td>\n      <td>Unf</td>\n      <td>1941<        /td>\n              <td>...</td>\n      <td>Fa</        td>\n      <td>9490<        /td>\n              <t        d>79</td>\n      <        td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>6</td>\n      <td>806</td        >\n              <td>1941</td>\n      <td>      1950</td>\n    </tr>      \n    <tr>\n      <      th>2</t    h>\n      <td>979</td>\n          <td>224</td>\n            <td>3</td>\n              <td>No</td>\n      <td>185<      /td>\n      <td>LwQ</td>\n            <td>524</td>\n      <td>352</td>\n      <td>Unf</td>\n      <td>1950</td>\n      <td>...</td>\n      <td>Gd</td>\n      <td>7015</td>\n      <td>69</td>\n      <td>161</td>\n      <td>0</td>\n      <td>4</td      >\n          <td>5</    td>\n            <td>      709</td>\n      <td>      1950</td>\n      <td>1950</td>\      n    </tr>\n    <tr>\n                        <th>3</th>          \n      <td>1156</td          >\n      <td>866</td>\n      <t          d>4</td>\n      <t            d>No</            td>\n      <            td>392</td>\n                  <td>BLQ</td>\n      <td>768<            /td>\n                  <td>505</td>\n      <td>Fin</td            >\n      <td>197          7</td>        \n            <td>...</td>\n            <td>TA</td>\n      <td>10005</td>\n      <td>83</t        d>\n      <td>        299</td>\n      <td>117</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1160</td>\n      <td>1977</td>\n      <td>1977</td>\        n    </tr        >\n    <tr>\n      <th>4</th>\n              <td>525</td>\n                      <td>0</t        d>\n      <td>3</t        d>\n      <td>No</td>\n      <td>0</td>\n      <        td>Unf</t        d>\n      <td>525</td>\n      <        td>264</td>\n      <        td>Unf        </td>\n              <td>1971</td>\n      <        td>...</td>\n      <td>TA</t        d>\n      <td>1680</td        >\n      <td>21</td        >\n      <        td>381</td>\n      <td>0</td>\n      <td>5<        /td>\n      <td>6</t        d>\n      <td>525</td>\n      <td>1971</td>\n      <td>1971</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 21 columns</p>\n</div>"
                    },
                    "metadata": {},
                    "execution_count": 12
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "TrainSet_df = pd.read_csv(\"outputs/datasets/cleaned/train/TrainSetCleaned.csv\")\n",
                "TestSet_df = pd.read_csv(\"outputs/datasets/cleaned/test/TestSetCleaned.csv\")\n",
                "\n",
                "# Check the first few rows of the DataFrame to confirm that it loaded correctly\n",
                "TrainSet_df.head()\n",
                "TestSet_df.head()"
            ]
        },
        {
            "source": [],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "First we look at encoding our categorical variables since many machine learning models require inputs to be numerical. Luckily, most of our variables are numerical already, but we do have 4 categorical variables that need to be converted into numerical form.\n",
                "\n",
                "We will use Ordinal Encoding. This method converts each category to a unique integer. It is suitable for ordinal variables, where there is an inherent order in the categories.\n",
                "\n",
                "Looking at our categorical variables:\n",
                "\n",
                "**BsmtExposure**, **BsmtFinType1**, **GarageFinish** seem to be ordinal variables as they indicate quality or condition, with 'None' likely representing a missing or not applicable condition.\n",
                "\n",
                "**KitchenQual** seems to be an ordinal variable as well, with an inherent order (Ex > Gd > TA > Fa). \n",
                "\n",
                "Great!"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "source": [
                "# Categorical encoding"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "output_type": "error",
                    "ename": "TypeError",
                    "evalue": "unhashable type: 'dict_keys'",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[14], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m TestSet_df_encoded \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(encoder\u001b[38;5;241m.\u001b[39mtransform(TestSet_df[categories_dict\u001b[38;5;241m.\u001b[39mkeys()]), columns\u001b[38;5;241m=\u001b[39mcategories_dict\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Replace the old categorical columns in the dataframes with the new encoded ones\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mTrainSet_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcategories_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m TrainSet_df_encoded\n\u001b[1;32m     28\u001b[0m TestSet_df[categories_dict\u001b[38;5;241m.\u001b[39mkeys()] \u001b[38;5;241m=\u001b[39m TestSet_df_encoded\n",
                        "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3645\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3643\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array(key, value)\n\u001b[1;32m   3644\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m-> 3645\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item_frame_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   3647\u001b[0m     is_list_like(value)\n\u001b[1;32m   3648\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique\n\u001b[1;32m   3649\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_indexer_for([key])) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(value)\n\u001b[1;32m   3650\u001b[0m ):\n\u001b[1;32m   3651\u001b[0m     \u001b[38;5;66;03m# Column to set is duplicated\u001b[39;00m\n\u001b[1;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n",
            "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:3770\u001b        [0m, in \u001        b[0;36mDataFrame._set_item        _frame_value\u001b[0;34m(self,         key, value        )\u001b      [0m\n\u001b[1;32    m   3767\u001b[0m \u001b[38;5;28m    self\u001b[39m\u      001b[38;5;241m.\u001b[39m_ensure_valid_index(value)\n\u001b[1;32m   3769\u001b[0m \u001b[38;5;66;        03m# align columns\u001b[39;00m\n\u001b[0;32m-> 3770\u001b[0m \u001b[38;5;28;01mif\u001b[3      9;00m \u001b[4      3mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b      [49m\u001b[38;5;28;43mself\u00    1b[39;49m\u001b[38;5;241;43m    .\u001b[39      ;49m\u0      01b[43      mcolumns\u001b[49m:\      n\u001b[1;32m   3771\u001b[0m           loc \u001b[38;5;241        m=\u00        1b[39m \        u001b[38;5;28mself        \u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   3772\u001b[0m     cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
            "File \u001b[0;32m~/.local/lib/pytho        n3.8/site-pack        ages/pandas/core/indexes/base.py:5008\u001b[0m, in \u001b[0;36mIndex.__contains__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4973\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;        5;21m__contain        s__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: A        ny) \u001b[38;        5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   4974\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4975\u001b[0m         \u001b[38;5;12        4;03m    Return a boolean indicating whether the provided key is in the index.\u001b[39;00m\n\u001b[1;32m   4976\u0        01b[0m \n\u001        b[0;32m   (...)\u        001b[0m\n        \u001b[1;32m   5006\u001b[0m \u        001b[38;5;124;03m            False        \u001b[3        9;00m\n\u001b[1;32        m   5007\u001b[0m \u001b[38;5;124        ;03m    \        "\"\"\u001b[39;00m\n\u001b[0;32        m-> 5008\u001b[0m             \u00        1b[38;5;        28;43mhash\u001b[39;49m\u00        1b[43m(\u001b[49m\u001b[43mke        y\u001b[49m\u001b[43m)        \u001b[49m\n\u001b[        1;32m   50        09\u001b[0m     \u001b[38;5;28;01m        try\u001b[39;00m:\n\u001b[1;32m           5010\u001b[0m         \u001b[38;5;28;01mreturn\u00        1b[39;00m key \u001b[38;5        ;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\n",
                        "\u001b[        0;31mTypeError\u001b[0m: unhashable type: 'dict_keys'"
                    ]
                }
            ],
            "source": [
                "from sklearn.preprocessing import OrdinalEncoder\n",
                "\n",
                "# Define a dictionary with the correct order of each category for each variable\n",
                "categories_dict = {\n",
                "    'BsmtExposure': ['None', 'No', 'Mn', 'Av', 'Gd'],\n",
                "    'BsmtFinType1': ['None', 'Unf', 'LwQ', 'Rec', 'BLQ', 'ALQ', 'GLQ'],\n",
                "    'GarageFinish': ['None', 'Unf', 'RFn', 'Fin'],\n",
                "    'KitchenQual': ['Fa', 'TA', 'Gd', 'Ex'],\n",
                "}\n",
                "\n",
                "# Convert dict_keys object to a list\n",
                "categories_list = list(categories_dict.keys())\n",
                "\n",
                "# Instantiate the encoder\n",
                "encoder = OrdinalEncoder(categories=list(categories_dict.values()))\n",
                "\n",
                "# Fit the encoder on the categorical columns of the training data\n",
                "encoder.fit(TrainSet_df[categories_dict.keys()])\n",
                "\n",
                "# Apply the en        coder to the training data\n",
                "TrainSet_df_encoded = pd.DataFrame(encoder.transform(TrainSet_df[categories_dict.keys()]), columns=categories_dict.keys())\n",
                "\n",
                "# Apply the encoder to the test data\n",
                "TestSet_df_encoded = pd.DataFrame(encoder.transform(TestSet_df[categories_dict.keys()]), columns=categories_dict.keys())\n",
                "\n",
                "# Replace the old categorical columns in the dataframes with the new encoded ones\n",
                "TrainSet_df[categories_dict.keys()] = TrainSet_df_encoded\n",
                "TestSet_df[categories_dict.keys()] = TestSet_df_encoded\n"
            ]
        },
        {
            "source": [
                "# Feature Engineering Analysis"
            ],
            "cell_type": "markdown",
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "import scipy.stats as stats\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "import pandas as pd\n",
                "import warnings\n",
                "from feature_engine import transformation as vt\n",
                "from feature_engine.outliers import Winsorizer\n",
                "from feature_engine.encoding import OrdinalEncoder\n",
                "sns.set(style=\"whitegrid\")\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "\n",
                "def FeatureEngineeringAnalysis(df, analysis_type='numerical'):\n",
                "    \"\"\"\n",
                "    - used for quick feature engineering on numerical and categorical variables\n",
                "    to decide which transformation c        an better transform the distribution shape\n",
                "    - Once transformed, use a reporting tool, like pandas-profiling, to evaluate distributions\n",
                "    \"\"\"\n",
                "    check_missing_values(df)\n",
                "    allowed_types = ['numerical', 'ordinal_encoder', 'outlier_winsorizer']\n",
                "    check_user_entry_on_analysis_type(analysis_type, allowed_types)\n",
                "    list_column_transformers = define_list_column_transformers(analysis_type)\n",
                "\n",
                "    # Loop in each variable and engineer the data according to the analysis type\n",
                "    df_feat_eng = pd.DataFrame([])\n",
                "    for column in df.columns:\n",
                "        # create additional columns (column_method) to apply the methods\n",
                "        df_feat_eng = pd.concat([df_feat_eng, df[column]], axis=1)\n",
                "        for method in list_column_transformers:\n",
                "            df_feat_eng[f\"{column}_{m        ethod}\"] = df[column]\n",
                "\n",
                "        # Apply transformers in respective column_transformers\n",
                "        df_feat_eng, list_applied_transformers = apply_transformers(\n",
                "            analysis_type, df_feat_eng, column)\n",
                "\n",
                "        # For each variable, assess how the transformations perform\n",
                "        transformer_evaluation(\n",
                "            column, list_applied_transformers, analysis_type, df_feat_eng)\n",
                "\n",
                "    return df_feat_eng\n",
                "\n",
                "\n",
                "def check_user_entry_on_analysis_type(analysis_type, allowed_types):\n",
                "    \"\"\" Check analysis type \"\"\"\n",
                "    if analysis_type is None:\n",
                "        raise SystemExit(\n",
                "            f\"You should pass analysis_type parameter as one of the following options: {allowed_types}\")\n",
                "    if analysis_type not in allowed_types:\n",
                "        raise SystemExit(\n",
                "            f\"analysis_type argument should be one of these options: {allowed_types}\")\n",
                "\n",
                "\n",
                "def check_missing_values(df):\n",
                "    if df.isna().sum().sum() != 0:\n",
                "        ra        ise SystemExit(\n",
                "            f\"There is a missing value in you        r dataset. P        lease hand        le that b        efore getting into         feature engineering.\")\n",
                "\n",
                "\n",
                "def define        _list_column_transformers(analysis_type):\n",
                "    \"\"\" Set suffix columns accordin        g to analysis_type\"\"\"\n",
                "    if analysis_type == 'numerical':\n",
                "        list        _column_transformers = [\n",
                "            \"log_e\", \"log_10\", \"reciprocal        \", \"power\", \"box_cox\", \"yeo_johnson\"]\n",
                "\n",
                "    elif analysis_type == 'ordinal_encoder':\n",
                "                list_column_t        ransformers = [\"ordinal_encoder\"]\n",
        "\        n",
                "    elif analysis_type == 'outlier_winsorizer':        \n",
                "                list_column_transformers = ['iq        r']\n",
                "\n",
                "    return list_column_transformers\n",
        "\        n",
        "\        n",
                "def apply_transformers(analysis_type, df_feat_eng, column):\n",
                "    for col in df_feat_eng.select_dtypes(include='categ        ory').columns:        \n",
                "        df_feat_eng[col] = df_feat_eng[c        ol].astype('object')\n",
                "\n",
                "    if analysis_type == 'numerical':\n",
                "        df_feat_eng, list_applied_tran        sformers = Fea        tEngineering_Numerical(\n",
                "            d        f_feat_eng, column)\n",
                "\n",
                "    elif analysis_type == 'outlier_winsorizer':\n",
                "        df_feat_eng, list_        applied_transf        ormers = FeatEngineering_OutlierWinsorizer(\n",
                "            df_feat_eng, column)\n",
                "\n",
                "    elif analysis_type == 'ordinal_encoder':\n",
                "        df_feat_eng, list_applied_transformers = FeatEngine        ering_C        ategor        icalEnco        der(\n",
                "                    df_feat_eng, column)\n",
                "\n",
                "    return df_feat_en        g, list_applied_tran        sforme        rs\n",
                "\n",
                "\n",
                "def transformer_eva        luation(column, list_a        pplied_transformers,         analysis_type, df_        feat_eng):\n",
                "    # For each va        riable, assess how the transformations perfor        m\n",
                "    print(f\"* Varia        ble Analyzed: {column}\")\n",
                "    print(f\"* Applied         transformation: {list_applied_transformers} \\n\")\n",
                "    for col in [column] + list_applied_transformers:\n",
                "\n",
                "        if analysis_type != 'ordinal_enco        der':\n",
                "            DiagnosticP        lots_Numerical(df_feat_eng, col)\n",
        "\        n",
                "                else:\n        ",
                "            if col == column:\n",
                "                Diagn        osticPlots_Categories(df        _feat_eng, col)\n",
                "            else:\n",
                "                DiagnosticPlots_N        umerical(df_feat_eng, col)\n",
                "\n",
                "        print(\"\\n\")\n",
                "\n        ",
                "\n",
                "def DiagnosticPlots_Categories(df_feat_eng, col):\n",
                "    plt.figure(figs        ize=(4, 3))\n",
                "    sns.countplot(data=df_feat_eng, x=col        , palette=[\n",
                "                  '#432371'], order=df_feat_eng[col].value_coun        ts().index)\n",
                "    plt.xticks(rotation=90)\n",
                "    plt.suptitl        e(f\"{col}\", fontsize=30, y=1.05)\n",
                "    plt.show()\n",
                "    print(\"\\n        \")\n",
                "\n",
                "\n",
                "def DiagnosticPlots_Numerical(df, variable):\n",
                "    f        ig, axes = plt.subplots(1, 3, figsize=(12, 4))\n        ",
                "    sns.histplot(data=df, x=var        iable, kde=True, element=\"step\", ax=axes[0])\n",
                "    stats.probplot(df[vari        able], dist=\"norm\", plot=axes[1])\n",
                "    sns.boxplot(x=df[variable],         ax=axes[2])\n",
                "\n",
                "    axes[0].set_title        ('Histogram')\n",
                "    axes[1].set_title('QQ Plot')\n",
                "            axes[2].set        _title('Boxplot')\n",
                "    fig.suptitle(f\"{variable}\", fontsize=30        , y=1.05)\n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "\n",
                "def FeatEngineering_Categori        calEncoder(df_        feat_eng, column):\n",
                "    list_methods_worked = []\n",
                "    try        :\n",
                "        encoder = OrdinalEncod        er(encoding_method='arbitrary', variables=[\n",
                "                                         f\"{column}_        ordinal_encoder\"])\n",
                "                df_feat_e        ng = encoder.f        it_transform(df_feat_eng)\n",
                "        list_methods_worked.append(f\"{colu        mn}_ordinal_encoder\")\n",
                "\n",
                "            except Exception:\n",
                "        d        f_feat_eng.drop([f\"{column}_ordinal_en        coder\"], axis=1, inplace=True)\n",
                "\n",
                "    return df_feat_eng, list_methods_worked\n",
                "\n",
                "\n",
                "def FeatEngineering_OutlierWinso        rizer(df_feat_eng, column):\n",
                "    list_methods_worked = []\n",
                "\n",
                "    # Winsorizer iqr\n",
                "    try:\n        ",
                "                disc = W        insorizer(\n",
                "            capping        _method='iqr', tail='both', fold=1.5, variables=        [f\"{column}_iqr\"])\n",
                "                df_feat_eng = disc.fit_transform(df_feat_eng)\n",
                "        list_methods_worked.append(f\"{column}_iqr\")\n",
                "            except Excepti        on:\n",
                "        df_feat_eng.drop([f\"{column}_iqr\"], axis=1, inplace=        True)\n",
                "\n",
                "    return df_feat_eng, list_methods_worked        \n",
                "\n",
                "\n",
                "def Feat        Engineering_Numerical(df_feat_eng, column):\n",
                "    list_methods_worked = []\n",
                "\n",
                "    # LogTransformer base e\n",
                "            try:\n",
                "        lt = vt.LogTransformer(variables=[f\"{colum        n}_log_e\"])\n",
                "        df_feat_eng = lt.fit_transform(df_fe        at_eng)\n",
                "        list_methods_worked.append(f\"{column}_log_e\"        )\n",
                "    except Exception:\n",
                "                df_feat_eng.        drop([f\"{column}_log_e\"], axis=1, inplace=True)        \n",
                "        \n",
                "            # LogTransformer base 10\n",
                "    try:\n",
                "        l        t = vt.LogTransformer(variables=[f\"{column}_log_10\"], base='10')\n",
                "                df_feat_eng = lt.fit_transform(df_feat_eng)\n",
                "        list        _methods_worke        d.append(f\"{column}_log_10\")\n",
                "    ex        cept Exception:\n",
                "        df_feat_eng.drop([f\"{column}_log_10\"], axis=1, inp        lace=True)\n",
                "\n",
                "    # Re        ciprocalTransf        ormer\n",
                "    try:\n",
                "        rt = vt.Reci        procalTransformer(variables=[f\"{column}_reciprocal\"])\n",
                "        df_feat_eng = rt.fit        _transform(df_feat_eng)\n",
                "        l        ist_methods_wo        rked.append(f\"{column}_reciprocal\")\n",
                "    exc        ept Exception:\n",
                "        df_feat_eng.drop([f\"{column}_reciprocal\"], axis=1, inplace=T        rue)\n",
                "\n",
                "    # PowerTra        nsformer\n",
                "    try:\n",
                "        pt = vt.PowerTransformer(        variables=[f\"        {column}_power        \"])\n",
                "        df_feat_eng = pt.fit_transform(df_feat_eng)\n",
                "        list_methods_        worked.append(f\"{column}_power\")\n",
                "    except Exception:\n",
                "        df_feat_eng.drop([f\"{column}_power\"], axis=        1, inplace=True)\n",
                "\n",
                "    # BoxCoxTransformer\n",
                "    tr        y:\n",
                "        bct = vt.BoxCoxTransformer(variables=[f\"{        column}_box_co        x\"])\n",
                "        df_feat_eng = bct.fit_transform(d        f_feat_eng)\n",
        "        list_methods_worked.append(f\"{colum        n}_box_cox\")\        n",
                "    except Exc        eption:\n",
                "        df_feat_eng.dr        op([f\"{column}_box_cox\"], axis=1, inplace=True)\n",
                "\n",
                "    # YeoJohnsonTransformer\        n",
                "    try:\n",
        "        yjt = vt.YeoJohnsonTransformer        (variables=[f\        "{column
                }_yeo_johnson\"])\n",
                "        df_        feat_eng = yjt        .fit_transform(df_feat_eng)\n",
                "        list_methods_w        orked.append(f\"{column}_yeo_johnson\")\n",
                "    except Exception:\n",
                "        df_feat_eng.dr        op([f\"{column}_yeo_johnson\"], axis=1, inplace=True)\n",
                "\n",
                "    ret        urn df_feat_eng, list_methods_worked"
            ]
        },
        {
            "cell_type": "code",
            "execution_c        ount": 6,
            "metadata": {},
            "outputs": [
                {
                    "ou        tput_type": "e        rror",
                    "ename": "NameError",
                    "evalue": "name 'df' is not defined",
                    "traceback": [
                    "\u001b[0;31m---------------------------------------------------------------------------\u        001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                         Traceback (most recent call last)",
                    "Cell \u00      1b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m--    --> 1\u001b[0m df_transformed \u001b[38;5;241m    =\u001b[39m FeatureEngineeringAnalysis(\u001b[43      mdf\u001b[49m, analysis_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;1      24m'\u001b[39m\u001b[38;5;124mnumeri      cal\u001b[39m\u001b[38;5;124      m'\u001b[39m)  \        u001b[38;5;66;03          m# replace 'numerical' with the analysis type you want\u001b[39;00m\n",
                        "\u001b[0;31mNameError\u001b[0m:           name 'df' is not defi          ned"
                    ]
                }
            ],
            "source": [
                "df_transformed = FeatureEn            gineeringAnalysis(df, analysis_type='numerical')  # replace 'numerical' with t            he analysis type you want\n"
            ]
        },
        {
            "cell_type": "            code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "sou          rce": []
        },
        {
            "cell        _type": "markdown",
            "metadata": {
                "id": "ltNetd085qHf"
            },
            "source      ": [
                "      # Next step"
            ]
        },
        {
            "cell_type": "markd        own",
            "metadata": {},
            "source": [
                "* Great! Now you can  push the changes to     your GitHub Repo, using the Git commands (gi      t add, git com      mit, git push)"
            ]
        }
    ],
    "metadata": {
        "      accelerator": "GPU",
        "colab": {
            "name": "Data Practitioner Jupyter Notebook.ipynb",
            "provenance": [],
            "toc_visible": true
        },
        "interpreter": {
            "hash": "8b8334dab9339717f72    7a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
        },
        "kernelspec      ": {
            "display_name": "Python       3.8.12 64-bit ('3.8.12': pyenv)",
            "name": "python381264bit3812pyenvc44d0ba3d4        d74926a1a78a      e71e39f6ac"
        },
        "language_info": {
            "codemirr      or_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "py      thon",
            "pygments      _lexer": "ipython3",
            "version": "3.8.12-final"
        },
        "orig_nbformat": 2
    },
    "nbformat": 4,
    "nbformat_minor": 2
}