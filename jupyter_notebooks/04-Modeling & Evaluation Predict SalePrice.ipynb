{
  "cells": [
    {
      "source": [
        "# **Notebook 4: Modeling & Evaluation**"
      ],
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fit and evaluate a regression model to predict prices on houses.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/collection/house_prices_records.csv\n",
        "* Instructions on which features to use for data cleaning and feature engineering can be found in respective notebooks.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Train set (features and target)\n",
        "* Test set (features and target)\n",
        "* Data cleaning and Feature Engineering pipeline\n",
        "* Modeling pipeline\n",
        "* Feature importance plot\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/workspaces/housing/jupyter_notebooks'"
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c",
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "You set a new current directory\n"
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "'/workspaces/housing'"
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Step 1: Load data"
      ]
    },
    {
      "source": [
        "Here we load the dataset and separate the target variable ('y') from the predictor variables ('X').\n",
        "\n"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(1460, 23)\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n0       856     854.0           3.0           No         706          GLQ   \n1      1262       0.0           3.0           Gd         978          ALQ   \n2       920     866.0           3.0           Mn         486          GLQ   \n\n   BsmtUnfSF  EnclosedPorch  GarageArea GarageFinish  ...  LotArea  \\\n0        150            0.0         548          RFn  ...     8450   \n1        284            NaN         460          RFn  ...     9600   \n2        434            0.0         608          RFn  ...    11250   \n\n   LotFrontage MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  \\\n0         65.0      196.0           61            5            7          856   \n1         80.0        0.0            0            8            6         1262   \n2         68.0      162.0           42            5            7          920   \n\n   WoodDeckSF  YearBuilt  YearRemodAdd  \n0         0.0       2003          2003  \n1         NaN       1976          1976  \n2         NaN       2001          2002  \n\n[3 rows x 23 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>1stFlrSF</th>\n      <th>2ndFlrSF</th>\n      <th>BedroomAbvGr</th>\n      <th>BsmtExposure</th>\n      <th>BsmtFinSF1</th>\n      <th>BsmtFinType1</th>\n      <th>BsmtUnfSF</th>\n      <th>EnclosedPorch</th>\n      <th>GarageArea</th>\n      <th>GarageFinish</th>\n      <th>...</th>\n      <th>LotArea</th>\n      <th>LotFrontage</th>\n      <th>MasVnrArea</th>\n      <th>OpenPorchSF</th>\n      <th>OverallCond</th>\n      <th>OverallQual</th>\n      <th>TotalBsmtSF</th>\n      <th>WoodDeckSF</th>\n      <th>YearBuilt</th>\n      <th>YearRemodAdd</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>856</td>\n      <td>854.0</td>\n      <td>3.0</td>\n      <td>No</td>\n      <td>706</td>\n      <td>GLQ</td>\n      <td>150</td>\n      <td>0.0</td>\n      <td>548</td>\n      <td>RFn</td>\n      <td>...</td>\n      <td>8450</td>\n      <td>65.0</td>\n      <td>196.0</td>\n      <td>61</td>\n      <td>5</td>\n      <td>7</td>\n      <td>856</td>\n      <td>0.0</td>\n      <td>2003</td>\n      <td>2003</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1262</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>Gd</td>\n      <td>978</td>\n      <td>ALQ</td>\n      <td>284</td>\n      <td>NaN</td>\n      <td>460</td>\n      <td>RFn</td>\n      <td>...</td>\n      <td>9600</td>\n      <td>80.0</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>8</td>\n      <td>6</td>\n      <td>1262</td>\n      <td>NaN</td>\n      <td>1976</td>\n      <td>1976</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>920</td>\n      <td>866.0</td>\n      <td>3.0</td>\n      <td>Mn</td>\n      <td>486</td>\n      <td>GLQ</td>\n      <td>434</td>\n      <td>0.0</td>\n      <td>608</td>\n      <td>RFn</td>\n      <td>...</td>\n      <td>11250</td>\n      <td>68.0</td>\n      <td>162.0</td>\n      <td>42</td>\n      <td>5</td>\n      <td>7</td>\n      <td>920</td>\n      <td>NaN</td>\n      <td>2001</td>\n      <td>2002</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows Ã— 23 columns</p>\n</div>"
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/collection/house_prices_records.csv\"))\n",
        "\n",
        "# Separate predictors and target\n",
        "X = df.drop(['SalePrice'], axis=1)\n",
        "y = df['SalePrice']\n",
        "\n",
        "print(X.shape)\n",
        "X.head(3)"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Step 2: ML Pipeline with all data"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "## ML pipeline for Data Cleaning and Feature Engineering"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Feature Engineering\n",
        "from feature_engine.selection import SmartCorrelatedSelection\n",
        "from feature_engine.encoding import OrdinalEncoder\n",
        "\n",
        "\n",
        "def PipelineDataCleaningAndFeatureEngineering():\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"OrdinalCategoricalEncoder\", OrdinalEncoder(encoding_method='arbitrary',\n",
        "                                                     variables=['gender', 'Partner', 'Dependents', 'PhoneService',\n",
        "                                                                'MultipleLines', 'InternetService', 'OnlineSecurity',\n",
        "                                                                'OnlineBackup', 'DeviceProtection', 'TechSupport',\n",
        "                                                                'StreamingTV', 'StreamingMovies', 'Contract',\n",
        "                                                                'PaperlessBilling', 'PaymentMethod'])),\n",
        "\n",
        "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
        "         method=\"spearman\", threshold=0.6, selection_method=\"variance\")),\n",
        "\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n",
        "\n",
        "\n",
        "PipelineDataCleaningAndFeatureEngineering()\n"
      ]
    },
    {
      "source": [
        "## ML Pipeline for Modelling and Hyperparameter Optimisation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feat Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feat Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def PipelineClf(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feat_selection\", SelectFromModel(model)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_base\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches"
      ]
    },
    {
      "source": [
        "## Split Train and Test Set"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    test_size=0.2,\n",
        "    random_state=0,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "source": [
        "# Next step: Notebook 2"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "In notebook 2 we will move on the the next next step in our data analysis process: Exploratory Data Analysis (EDA)."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [],
      "cell_type": "markdown",
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python381264bit3812pyenvc44d0ba3d4d74926a1a78ae71e39f6ac"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12-final"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}